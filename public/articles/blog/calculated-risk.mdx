---
title: AI — Walking the line of calculated risk
subtitle: Dec 19, 2024 • 5 min read
year: 2024
date: 2024-12-19
thumbnail: https://schultzdavidg-portfolio.s3.us-west-1.amazonaws.com/images/blog/ai-calculated-risk/moss.jpg
order: null
visible: true
---

<TitleSection />

AI's usefulness isn't in text prompts, it's in probabilistic calculation within the bounds of a contained constraint model.

![image](https://schultzdavidg-portfolio.s3.us-west-1.amazonaws.com/images/blog/ai-calculated-risk/moss.jpg)

So, right now we're doing everything within the bounds of text prompts, right? You write a message, it predicts the 'best' response, whatever. Everyone is asking, "what is that good for?" (and that's a good question. what *is* ai actually doing that's useful?)

The thing is, pure text prompts are not very useful. Sure, it can write code. Sure, it can complete your google search. But that's not *actually* replacing the tasks we want it to do. (Incidentally, people seem to be trying to use AI to replace the type of work humans *should* be doing. e.g. art! or, e.g. the discomfort of actually learning.)

Ultimately, what we want AI to do for us is make decisions we don't truly care about. If it can take on labor that humans don't need to do, then it frees us up to do so much more. But we need to be able to trust that it will execute those decisions correctly—and we generally can't right now. It's partially because it hasn't gotten good enough... but more fundamentally, it's because AI is a probabilistic system. And people haven't adjusted to this paradigm. I'm not currently seeing any products that have figured out how to work within the bounds of probabilistic design space.

Here's my theory: if we can put up gutter bumpers, we'll be able to progressively expand the extent of decision-making we give to it.

I think that people will eventually figure out that we can enable it to make progressively larger decisions if we focus on meeting it at the "right" level of probability. Right now, we need to reduce probability as much as possible, because we simply aren't ready to handle more. When we do this, and sharpen our understanding of a more constrained model—we will be better able to work within wider fields of probability.

So, ok. We let AI make probabilistic decisions for that. What does that even mean?

Well... let's think of an example. Think about an AR system. You have these glasses, and you have an AI agent onboard that *can see what you see.* It's like, fkn jarvis or whatever.

This AI agent could, say, manage a personal database for you. Let's say you go to the cafe, and you need the bathroom code. You could ask the agent to save it to your database, and remember that. Or, maybe you need the wifi code. The agent could automatically take a picture of the little sign they put up, and then automatically enter the wifi password on your phone. These micro-decisions—setting up a database, entering columns and key-value pairs—these things suck! This is labor that, ultimately, is not useful to us.

but an AI could. you wouldn't have to worry about setting up your spreadsheet columns or anything--the AI manages it for you. it boils down to inputs, and probabilistic outputs. and i think you could create something really cool with that

So—how do you actually support an AI *agent* to accept input and produce probabilistic outputs?Well let me tell you, it's not gonna be a text prompt every time. It's gonna be a service that develops a container—a set of constraints—which provide a framework for the AI to make decisions. It's gonna be people who prompt the AI with a complex set of words that tell it, very specifically, how it should make decisions.

And the final, key part here is that users wouldn't interact with the AI by giving it text prompts. (which is good, because it stops prompt injection) Users will interact with it under very defined rules. Like, give it a string of binary 010101, and then use that to estimate the best response.

And that's really fucking powerful. Everyone rn is focused on probabilistic input → deterministic output... But that's the wrong way to look at it, man. The right way is to approach it as: deterministic input → probabilistic output. This is the next wave. Haven't seen anyone talk about it yet. But I imagine we'll start to see this approach pop up, in the next few years.